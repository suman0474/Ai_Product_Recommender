"""
Validation Tool for Product Search Workflow
============================================

Step 1 of Product Search Workflow:
- Detects product type from user input
- Loads or generates schema (with PPI workflow if needed)
- Validates requirements against schema
- Returns structured validation result

This tool integrates:
- Intent extraction (product type detection)
- Schema loading/generation (with PPI workflow)
- Requirements validation
"""

import logging
from typing import Dict, Any, Optional, List
import threading

# Configure logging
logger = logging.getLogger(__name__)

# Debug flags for validation tool debugging
try:
    from debug_flags import debug_log, timed_execution, is_debug_enabled
    DEBUG_AVAILABLE = True
except ImportError:
    DEBUG_AVAILABLE = False
    def debug_log(module, **kwargs):
        def decorator(func):
            return func
        return decorator
    def timed_execution(module, **kwargs):
        def decorator(func):
            return func
        return decorator
    def is_debug_enabled(module):
        return False

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘  [FIX #A1] SESSION-LEVEL ENRICHMENT DEDUPLICATION                       â•‘
# â•‘  Prevents redundant Standards RAG calls for same product in one session â•‘
# â•‘  Cache: product_type -> enrichment_result (thread-safe)                 â•‘
# â•‘  [PHASE 1] Using BoundedCache with TTL/LRU to prevent memory leaks      â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from agentic.infrastructure.caching.bounded_cache import get_or_create_cache, BoundedCache

_session_enrichment_cache: BoundedCache = get_or_create_cache(
    name="session_enrichment",
    max_size=200,           # Max 200 concurrent sessions
    ttl_seconds=1800        # 30 minute session TTL
)


def _get_session_enrichment(product_type: str, session_id: Optional[str] = None) -> Optional[Dict[str, Any]]:
    """
    Get cached enrichment result for this session.

    Args:
        product_type: Product type to look up
        session_id: Session identifier. If None, uses a global shared scope.
    """
    normalized_type = product_type.lower().strip()
    key = f"{session_id}:{normalized_type}" if session_id else normalized_type

    # BoundedCache is thread-safe internally, no lock needed
    return _session_enrichment_cache.get(key)


def _cache_session_enrichment(product_type: str, enrichment_result: Dict[str, Any], session_id: Optional[str] = None):
    """
    Cache enrichment result for this session.

    Args:
        product_type: Product type to cache
        enrichment_result: Data to cache
        session_id: Session identifier. If None, uses global shared scope.
    """
    normalized_type = product_type.lower().strip()
    key = f"{session_id}:{normalized_type}" if session_id else normalized_type

    # BoundedCache is thread-safe internally, no lock needed
    _session_enrichment_cache.set(key, enrichment_result)
    logger.info(f"[FIX #A1] Cached enrichment for {key} (size: {len(_session_enrichment_cache)})")


def clear_session_enrichment_cache():
    """Clear session enrichment cache (call at start of new session)."""
    # BoundedCache.clear() is thread-safe internally
    count = _session_enrichment_cache.clear()
    logger.info(f"[FIX #A1] Session enrichment cache cleared ({count} entries)")


class ValidationTool:
    """
    Validation Tool - Step 1 of Product Search Workflow

    Responsibilities:
    1. Extract product type from user input
    2. Load or generate product schema (PPI workflow if needed)
    3. Validate user requirements against schema
    4. Return structured validation result
    """

    def __init__(
        self,
        enable_ppi: bool = True,
        enable_phase2: bool = True,
        enable_phase3: bool = True,
        use_async_workflow: bool = True,
        enable_standards_enrichment: bool = True
    ):
        """
        Initialize the validation tool.

        Args:
            enable_ppi: Enable PPI workflow for schema generation
            enable_phase2: Enable Phase 2 parallel optimization
            enable_phase3: Enable Phase 3 async optimization (highest priority)
            use_async_workflow: Use new async SchemaWorkflow (recommended)
            enable_standards_enrichment: Enable Standards RAG enrichment (Step 1.2.1)
        """
        self.enable_ppi = enable_ppi
        self.enable_phase2 = enable_phase2
        self.enable_phase3 = enable_phase3
        self.use_async_workflow = use_async_workflow
        self.enable_standards_enrichment = enable_standards_enrichment

        logger.info("[ValidationTool] Initialized with PPI workflow: %s",
                   "enabled" if enable_ppi else "disabled")
        logger.info("[ValidationTool] Phase 2 optimization: %s",
                   "enabled" if enable_phase2 else "disabled")
        logger.info("[ValidationTool] Phase 3 async optimization: %s",
                   "enabled" if enable_phase3 else "disabled")
        logger.info("[ValidationTool] Standards enrichment: %s",
                   "enabled" if enable_standards_enrichment else "disabled")

    @timed_execution("VALIDATION_TOOL", threshold_ms=20000)
    @debug_log("VALIDATION_TOOL", log_args=True, log_result=False)
    def validate(
        self,
        user_input: str,
        expected_product_type: Optional[str] = None,
        session_id: Optional[str] = None,
        enable_standards_enrichment: Optional[bool] = None
    ) -> Dict[str, Any]:
        """
        Validate user input and requirements.

        Args:
            user_input: User's requirement description
            expected_product_type: Expected product type (optional, for validation)
            session_id: Session identifier (for logging/tracking)

        Returns:
            Validation result with:
            {
                "success": bool,
                "product_type": str,
                "schema": dict,
                "provided_requirements": dict,
                "missing_fields": list,
                "is_valid": bool,
                "ppi_workflow_used": bool,
                "schema_source": str,  # "azure", "ppi_workflow", or "default_fallback"
                "session_id": str
            }
        """
        logger.info("[ValidationTool] Starting validation")
        logger.info("[ValidationTool] Session: %s", session_id or "N/A")
        logger.info("[ValidationTool] Input: %s", user_input[:100] + "..." if len(user_input) > 100 else user_input)

        result = {
            "success": False,
            "session_id": session_id
        }

        # =====================================================================
        # FIX: Detect UI decision patterns BEFORE calling LLM
        # UI decisions like "User selected: continue" should not be processed
        # as product requirements. This prevents unnecessary LLM calls and
        # provides clearer error messages.
        # =====================================================================
        try:
            from debug_flags import is_ui_decision_input, get_ui_decision_error_message

            if is_ui_decision_input(user_input):
                logger.warning(f"[ValidationTool] UI decision pattern detected: '{user_input}'")
                logger.warning("[ValidationTool] This input should be routed to a different API endpoint")
                result.update({
                    "success": False,
                    "error": get_ui_decision_error_message(user_input),
                    "error_type": "UIDecisionPatternError",
                    "is_ui_decision": True,
                    "hint": "Use /api/agentic/run-analysis for 'continue' actions after requirements are collected"
                })
                return result
        except ImportError:
            # Fallback if debug_flags module not available
            ui_patterns = ["user selected:", "user clicked:", "decision:", "continue", "proceed"]
            normalized_input = user_input.lower().strip()
            for pattern in ui_patterns:
                if pattern in normalized_input or normalized_input == pattern:
                    logger.warning(f"[ValidationTool] UI decision pattern detected: '{user_input}'")
                    result.update({
                        "success": False,
                        "error": f"Input '{user_input}' is a UI action, not a product requirement. Please provide product specifications.",
                        "error_type": "UIDecisionPatternError",
                        "is_ui_decision": True
                    })
                    return result

        try:
            # Import required tools
            from tools.schema_tools import load_schema_tool, validate_requirements_tool
            from tools.intent_tools import extract_requirements_tool

            # =================================================================
            # STEP 1.1: EXTRACT PRODUCT TYPE
            # =================================================================
            logger.info("[ValidationTool] Step 1.1: Extracting product type")

            extract_result = extract_requirements_tool.invoke({
                "user_input": user_input
            })

            product_type = extract_result.get("product_type") or expected_product_type or ""
            
            # Handle case when LLM extraction failed (quota exceeded, API error, etc.)
            if not product_type:
                logger.error("[ValidationTool] âœ— Product type extraction failed - no product type detected")
                logger.error("[ValidationTool] âœ— User input was: %s", user_input[:200])

                # Check if input looks like requirements or just noise
                has_product_words = any(word in user_input.lower() for word in [
                    "transmitter", "sensor", "meter", "gauge", "valve", "pump",
                    "analyzer", "controller", "switch", "indicator", "recorder"
                ])

                if has_product_words:
                    error_msg = (
                        "Could not determine product type from your input. "
                        "The LLM service may be temporarily unavailable. Please try again."
                    )
                else:
                    error_msg = (
                        "No product type detected in your input. "
                        "Please describe what product you need (e.g., 'I need a pressure transmitter with 4-20mA output')."
                    )

                result.update({
                    "success": False,
                    "error": error_msg,
                    "error_type": "ProductTypeExtractionError",
                    "user_input_preview": user_input[:100] + "..." if len(user_input) > 100 else user_input
                })
                return result
            
            logger.info("[ValidationTool] âœ“ Detected product type: %s", product_type)

            # Validate against expected type if provided
            if expected_product_type and product_type and product_type.lower() != expected_product_type.lower():
                logger.warning(
                    "[ValidationTool] âš  Product type mismatch - Expected: %s, Detected: %s",
                    expected_product_type,
                    product_type
                )

            # =================================================================
            # STEP 1.2: LOAD OR GENERATE SCHEMA
            # =================================================================
            logger.info("[ValidationTool] Step 1.2: Loading/generating schema")

            schema_result = load_schema_tool.invoke({
                "product_type": product_type,
                "enable_ppi": self.enable_ppi
            })

            schema = schema_result.get("schema", {})
            schema_source = schema_result.get("source", "unknown")
            ppi_used = schema_result.get("ppi_used", False)
            from_database = schema_result.get("from_database", False)

            # Log schema source
            if from_database:
                logger.info("[ValidationTool] âœ“ Schema loaded from Azure Blob Storage")
            elif ppi_used:
                logger.info("[ValidationTool] âœ“ Schema generated via PPI workflow")
            else:
                logger.warning("[ValidationTool] âš  Using default schema (fallback)")

            # =================================================================
            # STEP 1.2.1: ENRICH SCHEMA WITH STANDARDS RAG (FIELD VALUES + STANDARDS SECTION)
            # Uses both tools.standards_enrichment_tool and agentic.standards_rag_enrichment
            # =================================================================
            if enable_standards_enrichment is None:
                enable_standards_enrichment = self.enable_standards_enrichment

            standards_info = None
            enrichment_result = None
            standards_rag_invoked = False
            standards_rag_invocation_time = None

            if enable_standards_enrichment:
                try:
                    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                    # â•‘           ðŸ”µ STANDARDS RAG INVOCATION STARTING ðŸ”µ            â•‘
                    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    import datetime
                    standards_rag_invocation_time = datetime.datetime.now().isoformat()
                    logger.info("="*70)
                    logger.info("STANDARDS RAG INVOKED")
                    logger.info(f"   Timestamp: {standards_rag_invocation_time}")
                    logger.info(f"   Product Type: {product_type}")
                    logger.info(f"   Session: {session_id}")
                    logger.info("="*70)
                
                    standards_rag_invoked = True
                    logger.info("[ValidationTool] Step 1.2.1: Enriching schema with Standards RAG")

                    # FIX #5: Import with fallback for missing modules
                    try:
                        from tools.standards_enrichment_tool import (
                            get_applicable_standards,
                            populate_schema_fields_from_standards
                        )
                    except ImportError as e:
                        logger.warning(f"[FIX5] Failed to import from tools.standards_enrichment_tool: {e}")
                        from tools.standards_enrichment_tool import get_applicable_standards
                        def populate_schema_fields_from_standards(product_type, schema):
                            """Fallback for missing function"""
                            logger.info("[FIX5] Using fallback for populate_schema_fields_from_standards")
                            return schema

                    try:
                        from agentic.workflows.standards_rag.standards_rag_enrichment import (
                            enrich_identified_items_with_standards,
                            is_standards_related_question
                        )
                    except ImportError as e:
                        logger.warning(f"[FIX5] Failed to import from standards_rag_enrichment: {e}")
                        def enrich_identified_items_with_standards(*args, **kwargs):
                            """Fallback for missing function"""
                            logger.info("[FIX5] Using fallback for enrich_identified_items_with_standards")
                            return {"success": False}

                        def is_standards_related_question(*args, **kwargs):
                            """Fallback for missing function"""
                            return False

                    # NOTE: Deep Agent module removed (always returned 0/0 fields)
                    # Use Standards RAG enrichment instead, which is working and faster

                    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                    # â•‘  [FIX #A1] SESSION-LEVEL DEDUPLICATION                               â•‘
                    # â•‘  Check if product was already enriched in this session               â•‘
                    # â•‘  If yes: reuse cached result (saves 50-70 seconds!)                  â•‘
                    # â•‘  If no: do enrichment once and cache for reuse                       â•‘
                    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

                    # Check session cache first
                    cached_enrichment = _get_session_enrichment(product_type, session_id)

                    if cached_enrichment:
                        # âœ… SESSION CACHE HIT - Reuse previous enrichment result
                        logger.info(f"[FIX #A1] ðŸŽ¯ SESSION CACHE HIT for {product_type} - Reusing enrichment (saves 50-70s!)")
                        standards_info = cached_enrichment.get('standards_info')
                        enrichment_result = cached_enrichment.get('enrichment_result')
                        schema = cached_enrichment.get('schema', schema)

                        # Apply cached schema updates
                        if cached_enrichment.get('standards_section'):
                            schema['standards'] = cached_enrichment['standards_section']

                        print(f"\n{'='*70}")
                        print(f"ðŸŽ¯ [FIX #A1] SESSION CACHE HIT - Skipping redundant Standards RAG call")
                        print(f"   Product: {product_type}")
                        print(f"   Saves: ~50-70 seconds!")
                        print(f"{'='*70}\n")
                    else:
                        # âŒ SESSION CACHE MISS - Need to do enrichment
                        logger.info(f"[FIX #A1] ðŸ”´ SESSION CACHE MISS for {product_type} - Running enrichment")

                        # Step 1.2.1a: POPULATE field values from Standards RAG (using tools module)
                        if not schema.get("_standards_population"):
                            logger.info("[ValidationTool] Step 1.2.1a: Populating schema field values from standards")
                            schema = populate_schema_fields_from_standards(product_type, schema)
                            fields_populated = schema.get("_standards_population", {}).get("fields_populated", 0)
                            logger.info(f"[ValidationTool] âœ“ Populated {fields_populated} fields with standards values")
                        else:
                            logger.info("[ValidationTool] âœ“ Schema already has standards-populated field values")

                        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                        # â•‘  [FIX #4] APPLY COMPREHENSIVE STANDARDS DEFAULTS (60+ FIELDS)           â•‘
                        # â•‘  Uses schema_field_extractor.py with 50-80 defaults per product type    â•‘
                        # â•‘  Fills gaps with IEC, ISO, ASME, NAMUR standards-referenced values      â•‘
                        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        try:
                            from agentic.deep_agent.schema.generation.field_extractor import extract_schema_field_values_from_standards

                            logger.info("[FIX #4] Applying comprehensive standards defaults (target: 60+ fields)")
                            fields_before = schema.get("_standards_population", {}).get("fields_populated", 0)

                            # Apply comprehensive defaults (50-80 fields per product type)
                            schema = extract_schema_field_values_from_standards(product_type, schema)

                            fields_after = schema.get("_schema_field_extraction", {}).get("fields_populated", 0)
                            total_fields = schema.get("_schema_field_extraction", {}).get("fields_total", 0)

                            logger.info(f"[FIX #4] âœ“ Standards defaults applied: {fields_before} â†’ {fields_before + fields_after} fields")
                            logger.info(f"[FIX #4] âœ“ Total schema fields: {total_fields}, Populated: {fields_before + fields_after}")

                            logger.info("="*70)
                            logger.info("[FIX #4] COMPREHENSIVE STANDARDS DEFAULTS APPLIED")
                            logger.info(f"   Before: {fields_before} fields")
                            logger.info(f"   After: {fields_before + fields_after} fields (target: 60+)")
                            logger.info(f"   Source: schema_field_extractor.py (IEC, ISO, ASME, NAMUR standards)")
                            logger.info("="*70)

                        except ImportError as e:
                            logger.warning(f"[FIX #4] schema_field_extractor not available: {e}")
                        except Exception as e:
                            logger.warning(f"[FIX #4] Standards defaults application failed: {e}")

                        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                        # â•‘  [FIX #5] APPLY TEMPLATE SPECIFICATIONS (62+ FIELDS PER PRODUCT)        â•‘
                        # â•‘  Uses specification_templates.py with structured spec definitions       â•‘
                        # â•‘  Provides comprehensive coverage with importance levels & typical valuesâ•‘
                        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        try:
                            from agentic.deep_agent.specifications.templates.templates import (
                                get_all_specs_for_product_type,
                                export_template_as_dict
                            )

                            # Get template specifications for this product type
                            template_specs = get_all_specs_for_product_type(product_type)

                            if template_specs:
                                logger.info(f"[FIX #5] Applying template specifications ({len(template_specs)} specs)")

                                # Create or update template_specifications section in schema
                                if "template_specifications" not in schema:
                                    schema["template_specifications"] = {}

                                # Add template spec values as defaults for empty fields
                                specs_added = 0
                                for spec_key, spec_def in template_specs.items():
                                    # Check if this field is already populated
                                    field_exists = False
                                    for section in ["mandatory", "optional", "Performance", "Electrical", "Mechanical"]:
                                        if section in schema and spec_key in schema[section]:
                                            field_exists = True
                                            break

                                    if not field_exists and spec_def.typical_value:
                                        # Add to template_specifications section
                                        schema["template_specifications"][spec_key] = {
                                            "value": str(spec_def.typical_value),
                                            "unit": spec_def.unit or "",
                                            "category": spec_def.category,
                                            "description": spec_def.description,
                                            "importance": spec_def.importance.name if hasattr(spec_def.importance, 'name') else "OPTIONAL",
                                            "source": "template_specification"
                                        }
                                        specs_added += 1

                                logger.info(f"[FIX #5] âœ“ Added {specs_added} template specifications")
                                schema["_template_specs_added"] = specs_added

                                logger.info("="*70)
                                logger.info("[FIX #5] TEMPLATE SPECIFICATIONS APPLIED")
                                logger.info(f"   Template specs available: {len(template_specs)}")
                                logger.info(f"   New specs added: {specs_added}")
                                logger.info(f"   Source: specification_templates.py")
                                logger.info("="*70)
                            else:
                                logger.debug(f"[FIX #5] No template found for product type: {product_type}")

                        except ImportError as e:
                            logger.debug(f"[FIX #5] specification_templates not available: {e}")
                        except Exception as e:
                            logger.warning(f"[FIX #5] Template specifications application failed: {e}")

                        # Step 1.2.1b: GET applicable standards for standards section (using tools module)
                        standards_info = get_applicable_standards(product_type, top_k=5)

                        enrichment_result = None
                        standards_section = None

                        if standards_info.get('success'):
                            # Add standards to schema if not already present
                            if 'standards' not in schema:
                                standards_section = {
                                    'applicable_standards': standards_info.get('applicable_standards', []),
                                    'certifications': standards_info.get('certifications', []),
                                    'safety_requirements': standards_info.get('safety_requirements', {}),
                                    'calibration_standards': standards_info.get('calibration_standards', {}),
                                    'environmental_requirements': standards_info.get('environmental_requirements', {}),
                                    'communication_protocols': standards_info.get('communication_protocols', []),
                                    'sources': standards_info.get('sources', []),
                                    'confidence': standards_info.get('confidence', 0.0)
                                }
                                schema['standards'] = standards_section

                            num_standards = len(standards_info.get('applicable_standards', []))
                            num_certs = len(standards_info.get('certifications', []))
                            logger.info(f"[ValidationTool] âœ“ Standards enriched: {num_standards} standards, {num_certs} certifications")

                            # Log success indicator
                            logger.info("="*70)
                            logger.info("STANDARDS RAG COMPLETED SUCCESSFULLY")
                            logger.info(f"   Standards Found: {num_standards}")
                            logger.info(f"   Certifications Found: {num_certs}")
                            logger.info("="*70)
                        else:
                            logger.warning(f"[ValidationTool] Standards RAG returned no results: {standards_info.get('error', 'Unknown')}")

                        # Step 1.2.1c: ENRICH with normalized category using agentic module
                        # This provides structured standards_info with normalized_category for the product type
                        try:
                            # Create a mock item representing this product type for enrichment
                            product_item = [{
                                "name": product_type,
                                "category": product_type,
                                "specifications": schema.get("mandatory", {})
                            }]

                            enriched_items = enrich_identified_items_with_standards(
                                items=product_item,
                                product_type=product_type,
                                top_k=3
                            )

                            if enriched_items and len(enriched_items) > 0:
                                enrichment_result = enriched_items[0].get("standards_info", {})

                                # Add normalized category to schema if available
                                if enriched_items[0].get("normalized_category"):
                                    schema["normalized_category"] = enriched_items[0]["normalized_category"]
                                    logger.info(f"[ValidationTool] âœ“ Normalized category: {schema['normalized_category']}")

                                # Merge additional enrichment info into standards section
                                if enrichment_result.get("enrichment_status") == "success":
                                    if "standards" in schema:
                                        # Merge communication protocols if new ones found
                                        existing_protocols = set(schema["standards"].get("communication_protocols", []))
                                        new_protocols = set(enrichment_result.get("communication_protocols", []))
                                        schema["standards"]["communication_protocols"] = list(existing_protocols | new_protocols)

                                        # Merge certifications if new ones found
                                        existing_certs = set(schema["standards"].get("certifications", []))
                                        new_certs = set(enrichment_result.get("certifications", []))
                                        schema["standards"]["certifications"] = list(existing_certs | new_certs)

                                    logger.info("[ValidationTool] âœ“ Additional enrichment merged from standards_rag_enrichment")

                        except Exception as enrich_err:
                            logger.debug(f"[ValidationTool] Additional enrichment skipped: {enrich_err}")
                            # Non-critical - continue without additional enrichment

                        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                        # â•‘  [FIX #A1] CACHE ENRICHMENT RESULT FOR SESSION               â•‘
                        # â•‘  Store for reuse in subsequent validation/enrichment calls   â•‘
                        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        enrichment_cache_data = {
                            'standards_info': standards_info,
                            'enrichment_result': enrichment_result,
                            'schema': schema,
                            'standards_section': schema.get('standards')
                        }
                        _cache_session_enrichment(product_type, enrichment_cache_data, session_id)
                        logger.info(f"[FIX #A1] ðŸ’¾ Cached enrichment result for {product_type} (Session: {session_id})")

                    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
                    # â•‘  [NEW] DEEP AGENT SCHEMA POPULATION WITH FAILURE MEMORY                   â•‘
                    # â•‘  Uses SchemaGenerationDeepAgent with learning from past failures          â•‘
                    # â•‘  - Parallel multi-source generation                                       â•‘
                    # â•‘  - Adaptive prompts based on history                                      â•‘
                    # â•‘  - Recovery from failures using learned patterns                          â•‘
                    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    logger.info("[ValidationTool] Step 1.2.1d: Deep Agent schema population starting")
                    logger.info("="*70)
                    logger.info("[DEEP AGENT] SCHEMA POPULATION STARTING")
                    logger.info(f"   Product: {product_type}")
                    logger.info("="*70)

                    try:
                        from agentic.deep_agent.schema.populator_legacy import (
                            populate_schema_with_deep_agent,
                            predict_population_success
                        )

                        # Predict success rate before attempting
                        prediction = predict_population_success(product_type)
                        logger.info(f"[ValidationTool] Deep Agent risk level: {prediction.get('risk_level', 'unknown')}")

                        # Run deep agent population
                        schema, population_stats = populate_schema_with_deep_agent(
                            product_type=product_type,
                            schema=schema,
                            session_id=session_id,
                            use_memory=True
                        )

                        fields_populated = population_stats.get("fields_populated", 0)
                        total_fields = population_stats.get("total_fields", 0)
                        sources = population_stats.get("sources_used", [])

                        logger.info(f"[ValidationTool] âœ“ Deep Agent populated {fields_populated}/{total_fields} fields")
                        logger.info(f"[ValidationTool] âœ“ Sources: {', '.join(sources) if sources else 'none'}")

                        print("\n" + "="*70)
                        print("[DEEP_AGENT] SCHEMA POPULATION COMPLETED")
                        print(f"   Fields Populated: {fields_populated}/{total_fields}")
                        print(f"   Sources Used: {len(sources)}")
                        print("="*70 + "\n")

                    except ImportError as e:
                        logger.warning(f"[FIX5] Module not found - deep_agent_schema_populator: {e}")
                        logger.info("[FIX5] Using fallback for populate_schema_with_deep_agent")
                        print("\n" + "="*70)
                        print("[DEEP_AGENT] SCHEMA POPULATION COMPLETED (fallback)")
                        print("   Fields Populated: 0/0")
                        print("   Sources Used: 0")
                        print("="*70 + "\n")
                    except Exception as e:
                        logger.warning(f"[ValidationTool] Deep Agent population failed (non-critical): {e}")
                        print("\n" + "="*70)
                        print(f"[DEEP_AGENT] POPULATION FAILED: {str(e)[:50]}")
                        print("="*70 + "\n")

                except Exception as standards_error:
                    logger.error(f"[ValidationTool] Standards enrichment failed (non-critical): {standards_error}", exc_info=True)
                    # Continue without standards - this is non-critical

            # NOTE: Strategy RAG is NOT applied during initial validation.
            # Strategy-based vendor filtering is applied during Final Vendor Analysis
            # in vendor_analysis_tool.py to filter/prioritize vendors before analysis.
            strategy_info = None  # Placeholder for result compatibility


            # =================================================================
            # STEP 1.3: VALIDATE REQUIREMENTS
            # =================================================================
            logger.info("[ValidationTool] Step 1.3: Validating requirements")

            validation_result = validate_requirements_tool.invoke({
                "user_input": user_input,
                "product_type": product_type,
                "schema": schema
            })

            provided_requirements = validation_result.get("provided_requirements", {})
            missing_fields = validation_result.get("missing_fields", [])
            is_valid = validation_result.get("is_valid", False)

            # =================================================================
            # FIX: PROPAGATE REFINED PRODUCT TYPE
            # If validate_requirements_tool refined the product type (e.g.,
            # "Industrial Instrument" -> "flow meter"), use the refined type
            # for all subsequent operations including vendor analysis.
            # =================================================================
            refined_product_type = validation_result.get("product_type")
            product_type_was_refined = validation_result.get("product_type_refined", False)

            if refined_product_type and refined_product_type != product_type:
                logger.info(
                    "[ValidationTool] FIX: Product type REFINED by validation: '%s' -> '%s'",
                    product_type, refined_product_type
                )
                product_type = refined_product_type
                product_type_was_refined = True
            elif product_type_was_refined:
                logger.info(
                    "[ValidationTool] Product type was refined (already using: %s)",
                    product_type
                )

            # Log validation results
            if is_valid:
                logger.info("[ValidationTool] âœ“ All mandatory fields provided")
            else:
                logger.info("[ValidationTool] âš  Missing mandatory fields: %s", missing_fields)

            # =================================================================
            # BUILD RESULT
            # =================================================================
            result.update({
                "success": True,
                "product_type": product_type,  # This is now the refined product type if refinement occurred
                "product_type_refined": product_type_was_refined,  # FIX: Flag indicating refinement
                "original_product_type": extract_result.get("product_type"),  # FIX: Original detected type
                "normalized_category": schema.get("normalized_category"),  # From standards_rag_enrichment
                "schema": schema,
                "provided_requirements": provided_requirements,
                "missing_fields": missing_fields,
                "optional_fields": validation_result.get("optional_fields", []),
                "is_valid": is_valid,
                "ppi_workflow_used": ppi_used,
                "schema_source": schema_source,
                "from_database": from_database,
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # RAG INVOCATION TRACKING - Visible in browser Network tab
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                "rag_invocations": {
                    "standards_rag": {
                        "invoked": standards_rag_invoked,
                        "invocation_time": standards_rag_invocation_time,
                        "success": standards_info.get('success', False) if standards_info else False,
                        "product_type": product_type,
                        "results_count": len(standards_info.get('applicable_standards', [])) if standards_info else 0
                    },
                    "strategy_rag": {
                        "invoked": False,
                        "note": "Strategy RAG is applied in vendor_analysis_tool.py, not during validation"
                    }
                },
                # Standards RAG enrichment results (combined from tools and agentic modules)
                "standards_info": {
                    "applicable_standards": standards_info.get('applicable_standards', []) if standards_info else [],
                    "certifications": standards_info.get('certifications', []) if standards_info else [],
                    "communication_protocols": standards_info.get('communication_protocols', []) if standards_info else [],
                    "safety_requirements": standards_info.get('safety_requirements', {}) if standards_info else {},
                    "environmental_requirements": standards_info.get('environmental_requirements', {}) if standards_info else {},
                    "confidence": standards_info.get('confidence', 0.0) if standards_info else 0.0,
                    "sources": standards_info.get('sources', []) if standards_info else [],
                    "enrichment_success": standards_info.get('success', False) if standards_info else False,
                    # Additional data from standards_rag_enrichment module
                    "additional_enrichment": {
                        "status": enrichment_result.get("enrichment_status") if enrichment_result else "not_performed",
                        "merged_protocols": enrichment_result.get("communication_protocols", []) if enrichment_result else [],
                        "merged_certifications": enrichment_result.get("certifications", []) if enrichment_result else []
                    } if enrichment_result else None
                },
                # Strategy RAG enrichment results (TRUE RAG with vector store)
                "strategy_info": {
                    "preferred_vendors": strategy_info.get('preferred_vendors', []) if strategy_info else [],
                    "forbidden_vendors": strategy_info.get('forbidden_vendors', []) if strategy_info else [],
                    "neutral_vendors": strategy_info.get('neutral_vendors', []) if strategy_info else [],
                    "procurement_priorities": strategy_info.get('procurement_priorities', {}) if strategy_info else {},
                    "strategy_notes": strategy_info.get('strategy_notes', '') if strategy_info else '',
                    "confidence": strategy_info.get('confidence', 0.0) if strategy_info else 0.0,
                    "rag_type": strategy_info.get('rag_type', 'unknown') if strategy_info else 'not_performed',  # 'true_rag' or 'llm_inference'
                    "sources_used": strategy_info.get('sources_used', []) if strategy_info else [],
                    "enrichment_success": strategy_info.get('success', False) if strategy_info else False
                },
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # DEEP AGENT SCHEMA POPULATION - Section-based specifications
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                "deep_agent_info": {
                    "population_performed": schema.get("_deep_agent_population") is not None,
                    "fields_populated": schema.get("_deep_agent_population", {}).get("fields_populated", 0),
                    "total_fields": schema.get("_deep_agent_population", {}).get("total_fields", 0),
                    "sections_processed": schema.get("_deep_agent_population", {}).get("sections_processed", 0),
                    "sources_used": schema.get("_deep_agent_population", {}).get("sources_used", []),
                    "processing_time_ms": schema.get("_deep_agent_population", {}).get("processing_time_ms", 0),
                    # Section-based field values for UI display
                    "sections": schema.get("_deep_agent_sections", {})
                },
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                # [FIX #4 + #5] COMPREHENSIVE SCHEMA POPULATION INFO (60+ FIELDS)
                # Tracks fields from all sources for visibility
                # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                "schema_population_info": {
                    # FIX #3: Standards RAG extraction (regex-based)
                    "standards_rag_fields": schema.get("_standards_population", {}).get("fields_populated", 0),
                    # FIX #4: Comprehensive standards defaults (IEC, ISO, ASME, NAMUR)
                    "standards_defaults_fields": schema.get("_schema_field_extraction", {}).get("fields_populated", 0),
                    # FIX #5: Template specifications (62+ per product type)
                    "template_specs_fields": schema.get("_template_specs_added", 0),
                    # Total fields populated
                    "total_fields_populated": (
                        schema.get("_standards_population", {}).get("fields_populated", 0) +
                        schema.get("_schema_field_extraction", {}).get("fields_populated", 0) +
                        schema.get("_template_specs_added", 0)
                    ),
                    # Target achievement
                    "target_fields": 60,
                    "target_achieved": (
                        schema.get("_standards_population", {}).get("fields_populated", 0) +
                        schema.get("_schema_field_extraction", {}).get("fields_populated", 0) +
                        schema.get("_template_specs_added", 0)
                    ) >= 60,
                    # Sources used
                    "sources": [
                        "standards_rag_extraction" if schema.get("_standards_population") else None,
                        "schema_field_extractor_defaults" if schema.get("_schema_field_extraction") else None,
                        "specification_templates" if schema.get("_template_specs_added") else None
                    ]
                }
            })

            logger.info("[ValidationTool] âœ“ Validation completed successfully")
            return result

        except Exception as e:
            logger.error("[ValidationTool] âœ— Validation failed: %s", e, exc_info=True)
            result.update({
                "success": False,
                "error": str(e),
                "error_type": type(e).__name__
            })
            return result

    def get_schema_only(
        self,
        product_type: str,
        enable_ppi: Optional[bool] = None
    ) -> Dict[str, Any]:
        """
        Load or generate schema without validation.

        Args:
            product_type: Product type to get schema for
            enable_ppi: Override PPI setting (uses instance setting if None)

        Returns:
            Schema result with source information
        """
        logger.info("[ValidationTool] Loading schema for: %s", product_type)

        try:
            from tools.schema_tools import load_schema_tool

            schema_result = load_schema_tool.invoke({
                "product_type": product_type,
                "enable_ppi": enable_ppi if enable_ppi is not None else self.enable_ppi
            })

            logger.info("[ValidationTool] âœ“ Schema loaded from: %s",
                       schema_result.get("source", "unknown"))

            return schema_result

        except Exception as e:
            logger.error("[ValidationTool] âœ— Schema loading failed: %s", e, exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "schema": {}
            }

    def validate_with_schema(
        self,
        user_input: str,
        product_type: str,
        schema: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Validate user input against a provided schema.

        Args:
            user_input: User's requirement description
            product_type: Product type
            schema: Pre-loaded schema

        Returns:
            Validation result
        """
        logger.info("[ValidationTool] Validating with provided schema")

        try:
            from tools.schema_tools import validate_requirements_tool

            validation_result = validate_requirements_tool.invoke({
                "user_input": user_input,
                "product_type": product_type,
                "schema": schema
            })

            return {
                "success": True,
                "product_type": product_type,
                "provided_requirements": validation_result.get("provided_requirements", {}),
                "missing_fields": validation_result.get("missing_fields", []),
                "is_valid": validation_result.get("is_valid", False)
            }

        except Exception as e:
            logger.error("[ValidationTool] âœ— Validation failed: %s", e, exc_info=True)
            return {
                "success": False,
                "error": str(e)
            }

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PHASE 2: PARALLEL OPTIMIZATION METHODS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def validate_multiple_products_parallel(
        self,
        product_types: List[str],
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Generate schemas for multiple products in parallel (Phase 2 optimization).

        Use this when user needs schemas for multiple products at once.
        Example: "I need schemas for Temperature Transmitter, Pressure Gauge, Level Switch"

        Args:
            product_types: List of product types
            session_id: Session identifier

        Returns:
            Dictionary mapping product_type -> validation result
        """
        if not self.enable_phase2:
            logger.warning("[Phase 2] Parallel optimization disabled, falling back to sequential")
            return self._validate_sequentially(product_types, session_id)

        try:
            from agentic.deep_agent.schema.generation.parallel_generator import ParallelSchemaGenerator

            logger.info(f"[Phase 2] Starting parallel schema generation for {len(product_types)} products")

            generator = ParallelSchemaGenerator(max_workers=min(3, len(product_types)))
            schemas = generator.generate_schemas_in_parallel(product_types, force_regenerate=False)

            # Validate each schema
            results = {}
            for product_type, schema_result in schemas.items():
                if schema_result.get('success'):
                    results[product_type] = {
                        "success": True,
                        "product_type": product_type,
                        "schema": schema_result.get('schema'),
                        "schema_source": schema_result.get('source'),
                        "optimization": "phase2_parallel"
                    }
                else:
                    results[product_type] = {
                        "success": False,
                        "product_type": product_type,
                        "error": schema_result.get('error')
                    }

            logger.info(f"[Phase 2] Parallel generation completed for {len(results)} products")
            return results

        except ImportError:
            logger.warning("[Phase 2] Parallel Schema Generator not available, using sequential")
            return self._validate_sequentially(product_types, session_id)
        except Exception as e:
            logger.error(f"[Phase 2] Error in parallel validation: {e}")
            return self._validate_sequentially(product_types, session_id)

    def _validate_sequentially(
        self,
        product_types: List[str],
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """Fallback to sequential validation when parallel not available."""
        results = {}
        for product_type in product_types:
            result = self.validate(product_type, session_id=session_id)
            results[product_type] = result
        return results

    def enrich_schema_parallel(
        self,
        product_type: str,
        schema: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Enrich schema using parallel field group queries (Phase 2 optimization).

        Instead of querying Standards RAG sequentially for each field group,
        query all field groups in parallel (5x faster!).

        Args:
            product_type: Product type
            schema: Schema to enrich

        Returns:
            Enriched schema with populated fields
        """
        if not self.enable_phase2:
            logger.warning("[Phase 2] Parallel enrichment disabled")
            return schema

        try:
            from agentic.workflows.standards_rag.parallel_standards_enrichment import ParallelStandardsEnrichment

            logger.info(f"[Phase 2] Starting parallel enrichment for {product_type}")

            enricher = ParallelStandardsEnrichment(max_workers=5)
            enriched = enricher.enrich_schema_in_parallel(product_type, schema)

            logger.info(f"[Phase 2] Parallel enrichment completed for {product_type}")
            return enriched

        except ImportError:
            logger.warning("[Phase 2] Parallel Standards Enrichment not available")
            return schema
        except Exception as e:
            logger.error(f"[Phase 2] Error in parallel enrichment: {e}")
            return schema

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PHASE 3: ASYNC WORKFLOW (Complete Schema Lifecycle)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    async def get_or_generate_schema_async(
        self,
        product_type: str,
        session_id: Optional[str] = None,
        force_regenerate: bool = False
    ) -> Dict[str, Any]:
        """
        Get or generate schema using complete async workflow (Phase 3).

        Complete lifecycle:
        1. Check session cache (FIX #A1)
        2. Check database
        3. Generate via PPI (with Phase 1+2+3 optimizations)
        4. Enrich with standards (async parallel)
        5. Store to database
        6. Return to user

        This is the RECOMMENDED method for single or multiple products.

        Args:
            product_type: Product type to get schema for
            session_id: Session identifier
            force_regenerate: Force regeneration (skip caches)

        Returns:
            Dictionary with schema and metadata
        """

        if not self.enable_phase3:
            logger.warning("[Phase 3] Async workflow disabled")
            # Fall back to sync validation
            return self.validate(product_type, session_id=session_id)

        try:
            from agentic.workflows.schema.schema_workflow import SchemaWorkflow

            logger.info(f"[Phase 3] Starting async workflow for: {product_type}")

            workflow = SchemaWorkflow(use_phase3_async=True)
            result = await workflow.get_or_generate_schema(
                product_type,
                session_id=session_id,
                force_regenerate=force_regenerate
            )

            return result

        except ImportError:
            logger.warning("[Phase 3] SchemaWorkflow not available, falling back to Phase 2")
            return self.validate_multiple_products_parallel([product_type], session_id)
        except Exception as e:
            logger.error(f"[Phase 3] Error in async workflow: {e}")
            return self.validate(product_type, session_id=session_id)

    async def get_or_generate_schemas_batch_async(
        self,
        product_types: List[str],
        session_id: Optional[str] = None
    ) -> Dict[str, Dict[str, Any]]:
        """
        Get or generate schemas for multiple products concurrently (Phase 3).

        Uses async concurrent execution for multiple products with benefits:
        - All products generated concurrently
        - Shared database lookups
        - Combined enrichment queries
        - Non-blocking I/O throughout

        Expected Performance (3 products):
        - Before: (437 + 210) Ã— 3 = 1941 seconds
        - After Phase 3: 100-120 seconds (19x faster!)

        Args:
            product_types: List of product types
            session_id: Session identifier

        Returns:
            Dictionary mapping product_type -> schema result
        """

        if not self.enable_phase3:
            logger.warning("[Phase 3] Async batch disabled, using Phase 2")
            return self.validate_multiple_products_parallel(product_types, session_id)

        try:
            from agentic.workflows.schema.schema_workflow import SchemaWorkflow

            logger.info(f"[Phase 3] Starting async batch workflow for {len(product_types)} products")

            workflow = SchemaWorkflow(use_phase3_async=True)
            results = await workflow.get_or_generate_schemas_batch(
                product_types,
                session_id=session_id
            )

            logger.info(f"[Phase 3] Batch workflow completed")

            return results

        except ImportError:
            logger.warning("[Phase 3] SchemaWorkflow not available, falling back to Phase 2")

            # Fallback: Use Phase 2 in parallel
            results = {}
            for product_type in product_types:
                result = self.validate_multiple_products_parallel(
                    [product_type],
                    session_id
                )
                results.update(result)
            return results

        except Exception as e:
            logger.error(f"[Phase 3] Error in async batch workflow: {e}")

            # Fallback: Sequential validation
            results = {}
            for product_type in product_types:
                result = self.validate(product_type, session_id=session_id)
                results[product_type] = result
            return results


# ============================================================================
# STANDALONE USAGE EXAMPLE
# ============================================================================

def example_usage():
    """Example usage of ValidationTool"""
    print("\n" + "="*70)
    print("VALIDATION TOOL - STANDALONE EXAMPLE")
    print("="*70)

    # Initialize tool
    tool = ValidationTool(enable_ppi=True)

    # Example 1: Validate user input
    print("\n[Example 1] Validate user input:")
    result = tool.validate(
        user_input="I need a pressure transmitter with 4-20mA output, 0-100 PSI range",
        session_id="test_session_001"
    )

    print(f"âœ“ Success: {result['success']}")
    print(f"âœ“ Product Type: {result.get('product_type')}")
    print(f"âœ“ Valid: {result.get('is_valid')}")
    print(f"âœ“ Schema Source: {result.get('schema_source')}")
    print(f"âœ“ PPI Used: {result.get('ppi_workflow_used')}")
    print(f"âœ“ Missing Fields: {result.get('missing_fields', [])}")

    # Example 2: Get schema only
    print("\n[Example 2] Get schema only:")
    schema_result = tool.get_schema_only("flow meter")
    print(f"âœ“ Schema Source: {schema_result.get('source')}")
    print(f"âœ“ Has Mandatory Fields: {bool(schema_result.get('schema', {}).get('mandatory'))}")


if __name__ == "__main__":
    # Configure logging for standalone testing
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    example_usage()
